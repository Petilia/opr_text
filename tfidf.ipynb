{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>track</th>\n",
       "      <th>front_cam_ts</th>\n",
       "      <th>back_cam_ts</th>\n",
       "      <th>lidar_ts</th>\n",
       "      <th>northing</th>\n",
       "      <th>easting</th>\n",
       "      <th>tz</th>\n",
       "      <th>qx</th>\n",
       "      <th>qy</th>\n",
       "      <th>qz</th>\n",
       "      <th>qw</th>\n",
       "      <th>back_description</th>\n",
       "      <th>front_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1676034260851770</td>\n",
       "      <td>2023-02-10-08-04-19-twilight</td>\n",
       "      <td>1676034260821540</td>\n",
       "      <td>1676034260865870</td>\n",
       "      <td>1676034260851770</td>\n",
       "      <td>-23.839826</td>\n",
       "      <td>-17.655232</td>\n",
       "      <td>-1.474530</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>0.028187</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>This image shows a man standing on the stairs ...</td>\n",
       "      <td>This is a picture of a city street with buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1676034268718093</td>\n",
       "      <td>2023-02-10-08-04-19-twilight</td>\n",
       "      <td>1676034268687989</td>\n",
       "      <td>1676034268708533</td>\n",
       "      <td>1676034268718093</td>\n",
       "      <td>-19.060815</td>\n",
       "      <td>-19.003152</td>\n",
       "      <td>-2.513494</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.019243</td>\n",
       "      <td>-0.121944</td>\n",
       "      <td>0.992199</td>\n",
       "      <td>This image shows two people standing outside i...</td>\n",
       "      <td>The image shows a street with buildings on eit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         timestamp                         track   \n",
       "0           0  1676034260851770  2023-02-10-08-04-19-twilight  \\\n",
       "1           1  1676034268718093  2023-02-10-08-04-19-twilight   \n",
       "\n",
       "       front_cam_ts       back_cam_ts          lidar_ts   northing    easting   \n",
       "0  1676034260821540  1676034260865870  1676034260851770 -23.839826 -17.655232  \\\n",
       "1  1676034268687989  1676034268708533  1676034268718093 -19.060815 -19.003152   \n",
       "\n",
       "         tz        qx        qy        qz        qw   \n",
       "0 -1.474530  0.013051  0.028187  0.003870  0.999510  \\\n",
       "1 -2.513494  0.017344  0.019243 -0.121944  0.992199   \n",
       "\n",
       "                                    back_description   \n",
       "0  This image shows a man standing on the stairs ...  \\\n",
       "1  This image shows two people standing outside i...   \n",
       "\n",
       "                                   front_description  \n",
       "0  This is a picture of a city street with buildi...  \n",
       "1  The image shows a street with buildings on eit...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = \"/home/docker_opr/Datasets/splitted/train/train.csv\"\n",
    "\n",
    "df = pd.read_csv(train_csv_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfidf_pca(corpus, n_components=100, base_savepath=\"./opr/datasets/\"):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(corpus)\n",
    "    vectorized_corpus = vectorizer.transform(corpus).toarray()\n",
    "\n",
    "    pca =PCA(n_components=n_components)\n",
    "    pca.fit(vectorized_corpus)\n",
    "    \n",
    "    vectorizer_savepath = os.path.join(base_savepath, 'vectorizer.joblib')\n",
    "    pca_savepath = os.path.join(base_savepath, 'pca.joblib')\n",
    "    dump(vectorizer, vectorizer_savepath) \n",
    "    dump(pca, pca_savepath) \n",
    "\n",
    "def text_transform(self, text):\n",
    "    vect_data = self.vectorizer.transform([text]).toarray()\n",
    "    pca_data = self.pca.transform(vect_data)\n",
    "    pca_data = torch.tensor(pca_data, dtype=torch.float32)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.hstack((df[\"back_description\"], df[\"front_description\"]))\n",
    "train_tfidf_pca(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer, pca = train_tfidf_pca(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_savepath = \"./opr/datasets/\"\n",
    "vectorizer_savepath = os.path.join(base_savepath, 'vectorizer.joblib')\n",
    "pca_savepath = os.path.join(base_savepath, 'pca.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_savepath = \"./opr/datasets/\"\n",
    "vectorizer_savepath = os.path.join(base_savepath, 'vectorizer.joblib')\n",
    "pca_savepath = os.path.join(base_savepath, 'pca.joblib')\n",
    "\n",
    "vectorizer = load(vectorizer_savepath)\n",
    "pca = load(pca_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '10', '100', ..., 'zooms', 'вш', 'медничного'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_pipeline(corpus, n_components=300):\n",
    "#     pipe = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "#                      ('pca', PCA(n_components=n_components))])\n",
    "#     pipe.fit(corpus)\n",
    "#     return pipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
